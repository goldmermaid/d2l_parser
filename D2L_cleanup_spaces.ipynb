{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flexible-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "from d2lbook import config, markdown, utils, common\n",
    "import logging\n",
    "import re\n",
    "import glob\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "guilty-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkdownCleaning(object):\n",
    "    def __init__(self):\n",
    "        self.math_mapping = []\n",
    "        self.math_wholeline_mapping = []\n",
    "        self.backtick_mapping = []\n",
    "        self.english_no_ref_no_math = []\n",
    "        self.math_patterns = rf'\\$.*?\\$'\n",
    "        self.math_wholeline_patterns = r'\\$\\$[^$]*\\$\\$'\n",
    "        self.ref_pattern = r':[a-z]*:`[a-z_]*`'\n",
    "        self.html_pattern = r'(https[\\S]*)'\n",
    "        self.html_wrong_pattern = r'（https[\\S]*）'\n",
    "        self.backtick_pattern = r'`[^`]*`' # anything enclosed in two backticks\n",
    "        \n",
    "        \n",
    "    def remove_space(self, text:str) -> str:\n",
    "        text = text.replace(' ', '')\n",
    "        text = text.replace(\"(\", '（') # 半角到全角 half-width to full-width\n",
    "        text = text.replace(\")\", '）') # 半角到全角 half-width to full-width\n",
    "        return text\n",
    " \n",
    "    def record_math(self, text:str) -> str:  \n",
    "        \"\"\"\n",
    "        Example:\n",
    "        input text = \"$(\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ \"\n",
    "        self.math_mapping = ((\"$(\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ \", \n",
    "                              \"$(\\mathbf{X}\\in\\mathbb{R}^{n\\timesd}$\")) \n",
    "        \"\"\"\n",
    "        # find inline latex math match, record their original \n",
    "        # and \"removed space\" format in the mapping\n",
    "         \n",
    "        matched = set(re.findall(self.math_patterns, text))\n",
    "        for m in matched:\n",
    "            m_no_space = self.remove_space(m)\n",
    "            self.math_mapping.append((m, m_no_space))    \n",
    "        return matched\n",
    "\n",
    "    def record_wholeline_math(self, text:str) -> str:  \n",
    "        \"\"\"\n",
    "        Example:\n",
    "        input text = \"(**$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|.$$**)\"\n",
    "        \n",
    "        without this function, the spaces will be removed, hence,\n",
    "        \n",
    "        \n",
    "        self.math_mapping = ((\"(**$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|.$$**)\", \n",
    "                              \"(**$$\\|\\mathbf{x}\\|_1=\\sum_{i=1}^n\\left|x_i\\right|.$$**)\")) \n",
    "        \"\"\"\n",
    "        # find inline latex math match, record their original \n",
    "        # and \"removed space\" format in the mapping\n",
    "         \n",
    "        matched = set(re.findall(self.math_wholeline_patterns, text))\n",
    "        for m in matched:\n",
    "            m_no_space = self.remove_space(m)\n",
    "            self.math_wholeline_mapping.append((m, m_no_space))    \n",
    "        return matched\n",
    "    \n",
    "    def record_backtick(self, text:str) -> str:  \n",
    "        \"\"\"\n",
    "        Example:\n",
    "        input text = \"`x.reshape（3,-1）\"\n",
    "        self.backtick_mapping = ((\"`x.reshape（3,-1）\", \n",
    "                              \"`x.reshape(3,-1)\")) \n",
    "        \"\"\"\n",
    "        # find inline latex math match, record their original \n",
    "        # and \"removed space\" format in the mapping\n",
    "         \n",
    "        matched = set(re.findall(self.backtick_pattern, text))\n",
    "        for m in matched:\n",
    "            m_no_space = self.remove_space(m)\n",
    "            self.backtick_mapping.append((m, m_no_space))    \n",
    "        return matched\n",
    "        \n",
    "    def find_noref_nomath_english(self, text:str) -> str:\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        input text 1 = \"在(mdad da) :numref:`sec_linear_regression` 中我们介绍了线性回归mds ds。 \n",
    "                        mds那么小批量特征为 $(\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ ，\n",
    "                        权重为 $\\(mathbf{W} \\in \\mathbb{R}^{d \\times q}$。 \\n \"\n",
    "        output 1 = ['mdad da', 'mds ds', 'mds']\n",
    "        \n",
    "        input text 2: \"方程之一：*定理* (Bayes' theorem)。\"\n",
    "        output text 2: [\"Bayes' theorem\"]\n",
    "        \"\"\"\n",
    "        # find and replace inline references like\n",
    "        # numref:`...`, :eqref:`...`, :cite:`...` etc\n",
    "        text_ex_ref = re.sub(self.ref_pattern, '', text)\n",
    "        \n",
    "        # find and replace all inline math and references\n",
    "        text_ex_ref_ex_math = re.sub(self.math_patterns, '', text_ex_ref)\n",
    "        \n",
    "        # find all english in text, exclude inline math and references\n",
    "        list_of_english_no_ref_no_math = re.findall(r'[a-zA-Z][a-z A-Z\\']+[a-zA-Z]', text_ex_ref_ex_math)\n",
    "        \n",
    "        # find all english phases with space, record them in a list mapping\n",
    "        if len(list_of_english_no_ref_no_math)>0:\n",
    "            for eng in list_of_english_no_ref_no_math:\n",
    "                if \" \" in eng:\n",
    "                    eng_no_space = eng.replace(' ', '')\n",
    "                    self.english_no_ref_no_math.append((eng, eng_no_space))\n",
    "        return list_of_english_no_ref_no_math\n",
    "        \n",
    "    def recover_html_parentheses(self, text:str) -> str:\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        input text: 参见[关于分布的在线附录]（https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html）\n",
    "        output text: 参见[关于分布的在线附录](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html)\n",
    "        \"\"\"\n",
    "        wrong_html_matched = set(re.findall(self.html_wrong_pattern, text))\n",
    "        for html in wrong_html_matched:\n",
    "            if html[0]==\"（\" and html[-1]==\"）\":\n",
    "                corrected_html = \"(\" + html[1:-1] + \")\"\n",
    "                text = re.sub(html, corrected_html, text)\n",
    "        return text\n",
    "    \n",
    "    def recover_slides_symbol(self, text:str) -> str:\n",
    "        \"\"\"\n",
    "        The slides symbol in d2lbook needs to be half-width rather than full-width\n",
    "        \n",
    "        Example:\n",
    "        input text:  \"（**执行原地操作**）\"\n",
    "        output text: \"(**执行原地操作**)\"\n",
    "        \"\"\"       \n",
    "        text = text.replace(\"（**\", \"(**\")\n",
    "        text = text.replace(\"**）\", \"**)\")\n",
    "        text = text.replace(\"（~~\", \"(~~\")\n",
    "        text = text.replace(\"~~）\", \"~~)\")  \n",
    "        \n",
    "        text = text.replace(\"](~~\", \"] (~~\")\n",
    "        text = text.replace(\"](**\", \"] (**\")\n",
    "        \n",
    "        \n",
    "        return text\n",
    "        \n",
    "    def clean_and_recover(self, text:str) -> str:\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        input text 1: \"在(mdad da) :numref:`sec_linear_regression` 中我们介绍了线性回归mds ds。\n",
    "                     mds那么小批量特征为 $(\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ ，\n",
    "                     分布（参见[关于分布的在线附录](https://d2l.ai/chapter_appendix-mathematics-\n",
    "                     for-deep-learning/distributions.html)）模型中。 \\n \"\n",
    "        \n",
    "        output text 1: \"在（mdad da） :numref:`sec_linear_regression`中我们介绍了线性回归mds ds。\n",
    "                      mds那么小批量特征为$(\\\\mathbf{X} \\\\in \\\\mathbb{R}^{n \\times d}$，\n",
    "                      分布（参见[关于分布的在线附录](https://d2l.ai/chapter_appendix-mathematics-\n",
    "                      for-deep-learning/distributions.html)）模型中。\\n'\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        _ = self.record_math(text)\n",
    "        _ = self.record_wholeline_math(text)\n",
    "        _ = self.record_backtick(text)\n",
    "        \n",
    "        _ = self.find_noref_nomath_english(text)\n",
    "        text = self.remove_space(text)\n",
    "        \n",
    "        # recover all the math with spaces\n",
    "        for key, value in self.math_mapping:\n",
    "            text = text.replace(value, key)\n",
    " \n",
    "        # previous line failed to recover math in slides \"(** ... **)\",\n",
    "        # recover by the following line\n",
    "        for key, value in self.math_wholeline_mapping:\n",
    "            text = text.replace(value, key)\n",
    "\n",
    "        # recoverr backticks content\n",
    "        for key, value in self.backtick_mapping:\n",
    "            text = text.replace(value, key)  \n",
    "    \n",
    "        # recover all the reference (like :numref:`...`) with spaces\n",
    "        for key, value in self.english_no_ref_no_math:\n",
    "#             # add a space in front of reference key (like \"numref\", \"eqref\", \"cite\"),\n",
    "#             # or the html won't compile\n",
    "#             new_key = \" \"+key\n",
    "#             text = text.replace(value, new_key)\n",
    "            text = text.replace(value, key) \n",
    "    \n",
    "        # recover htmls wrong parentheses to be [xxx](htmls:...)\n",
    "        text = self.recover_html_parentheses(text)\n",
    "            \n",
    "        # recover some ref (or the html won't compile)\n",
    "        text = text.replace(\":numref:\", \" :numref:\")\n",
    "        text = text.replace(\":eqref:\", \" :eqref:\")\n",
    "        text = text.replace(\":cite:\", \" :cite:\")\n",
    "        \n",
    "        # recover slides symbols\n",
    "        text = self.recover_slides_symbol(text)\n",
    "        \n",
    "        return text\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "mc = MarkdownCleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "average-wagon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Bayes' theorem\"]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = \"方程之一：*定理* (Bayes' theorem)。\"\n",
    "eng = re.findall(r'[a-zA-Z][a-z A-Z\\']+[a-zA-Z]', ss)\n",
    "eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-regular",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "impressive-cologne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**$$\\|\\mathbf{X}\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}.$$**\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'(**$$\\\\|\\\\mathbf{X}\\\\|_F = \\\\sqrt{\\\\sum_{i=1}^m \\\\sum_{j=1}^n x_{ij}^2}.$$**)'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee = \"(**$$\\|\\mathbf{X}\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}.$$**)\"\n",
    "p = r'\\*\\*\\$\\$[^$]*\\$\\$\\*\\*'\n",
    "for n in re.findall(p, ee):\n",
    "    print(n)\n",
    "\n",
    "ee_out = mc.clean_and_recover(ee)\n",
    "ee_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "periodic-antigua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$$\\x0crac{d}{dx} [Cf(x)] = C \\x0crac{d}{dx} f(x),$$'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eee = \"$$\\frac{d}{dx} [Cf(x)] = C \\frac{d}{dx} f(x),$$\"\n",
    "eee_out = mc.clean_and_recover(eee)\n",
    "eee_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "comfortable-perry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在（mdad da） :numref:`sec_linear_regression`中我们介绍了线性回归mds ds。mds那么小批量特征为$(\\\\mathbf{X} \\\\in \\\\mathbb{R}^{n \\times d}$，分布（参见[关于分布的在线附录](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html)）模型中。\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = MarkdownCleaning()\n",
    "ex_text = \"在(mdad da) :numref:`sec_linear_regression` 中我们介绍了线性回归mds ds。 mds 那么小批量特征为 $(\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ ，分布（参见[关于分布的在线附录](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html)）模型中。 \\n \"\n",
    "# ex_text_encode = mt.record_math(ex_text)\n",
    "ex_text_nex = mc.clean_and_recover(ex_text)\n",
    "ex_text_nex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "pointed-attention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mdad da', 'mds ds', 'mds']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mc.find_noref_nomath_english(ex_text)\n",
    "# re.findall(r'[a-zA-Z][a-z A-Z]+', out)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "stone-attachment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mdad da', 'mdadda'),\n",
       " ('mds ds', 'mdsds'),\n",
       " ('mdad da', 'mdadda'),\n",
       " ('mds ds', 'mdsds')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.english_no_ref_no_math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "consistent-ranking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am from\n",
      "We should be friends\n",
      "softmax\n"
     ]
    }
   ],
   "source": [
    "sample = 'I am from 美国。We should be friends. 朋友softmax 。'\n",
    "for n in re.findall(r'[a-zA-Z][a-z A-Z]*[a-zA-Z]', sample):\n",
    "    print(n)\n",
    "\n",
    "# for n in re.findall(r'[\\u4e00-\\u9fff]+', sample):\n",
    "#     print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "square-buddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":numref:`sec_linear_regression`\n"
     ]
    }
   ],
   "source": [
    "for n in re.findall(r':[a-z]*:`[a-z_]*`', ex_text):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "french-sharing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "（https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html）\n"
     ]
    }
   ],
   "source": [
    "ex_html = \"分布（参见[关于分布的在线附录]（https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html））模型中\"\n",
    "for n in re.findall(r'（http[\\S]*html）', ex_html):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "polyphonic-desire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分布（参见[关于分布的在线附录](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html)）模型中'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_html = \"分布（参见[关于分布的在线附录]（https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html））模型中\"\n",
    "mc = MarkdownCleaning()\n",
    "ex_html_nex = mc.clean_and_recover(ex_html)\n",
    "ex_html_nex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-royalty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "shaped-competition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`x.reshape(-1,4)`\n",
      "`x.reshape(3,-1)`\n",
      "`x.reshape(3,4)`\n"
     ]
    }
   ],
   "source": [
    "example = \"在上面的例子中，我们可以用`x.reshape(-1,4)`或`x.reshape(3,-1)`来取代`x.reshape(3,4)`。\"\n",
    "\n",
    "for n in re.findall(r'`[^`]*`', example):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "anticipated-integration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在上面的例子中，我们可以用`x.reshape(-1,4)`或`x.reshape(3,-1)`来取代`x.reshape(3,4)`。'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mc.clean_and_recover(example)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "rising-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(**首先，我们导入`torch`'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example2 = \"（**首先，我们导入`torch`\"\n",
    "out = mc.clean_and_recover(example2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "split-supplement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(**首先，我们导入`torch`'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example2 = example2.replace(\"（**\", \"(**\")\n",
    "example2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-communist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-albania",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "trained-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator():\n",
    "    def _translate_markdown(self, text):\n",
    "            cells = markdown.split_markdown(text)\n",
    "            for cell in cells:\n",
    "                if cell['type'] == 'markdown':\n",
    "                    if 'class' in cell and cell['class']:\n",
    "                        # it may have nested code blocks\n",
    "                        cell['source'] = self._translate_markdown(cell['source'])\n",
    "                    else:\n",
    "                        text_cells = markdown.split_text(cell['source'])\n",
    "                        for t_cell in text_cells:\n",
    "#                             ipdb.set_trace()\n",
    "                            if t_cell['source'] and (\n",
    "                                t_cell['type'] in ['text', 'list']):\n",
    "                                text = t_cell['source']\n",
    "                                markdown_cleaning = MarkdownCleaning()\n",
    "                                t_cell['source'] = markdown_cleaning.clean_and_recover(text)\n",
    "#                                 if text.endswith('\\n'):\n",
    "#                                     t_cell['source'] += '\\n'\n",
    "                        cell['source'] = markdown.join_text(text_cells)\n",
    "            return markdown.join_markdown_cells(cells)\n",
    "\n",
    "    def translate_markdown(self, source_file: str, target_file: str):\n",
    "        with open(source_file, 'r') as r:\n",
    "            with open(target_file, 'w') as w:\n",
    "                w.write(self._translate_markdown(r.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "greenhouse-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_name = \"chapter_multilayer-perceptrons\" # \"chapter_linear-networks\"\n",
    "filename = \"kaggle-house-price\"\n",
    "\n",
    "src = \"/Users/rlhu/git_goldpiggy/parser/origin/{}/{}.md\".format(chapter_name, filename)\n",
    "tgt = \"/Users/rlhu/git_goldpiggy/d2l-zh/{}/{}.md\".format(chapter_name, filename)\n",
    "\n",
    "translator = Translator()\n",
    "translator.translate_markdown(src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "forced-scott",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rlhu/git_goldpiggy/parser\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-haiti",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-nomination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-kitchen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-thomson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fifty-modern",
   "metadata": {},
   "source": [
    "{'type': 'title', 'prefix': '# ', 'source': 'softmax回归', 'mark': ':label:`sec_softmax`\\n'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-settle",
   "metadata": {},
   "source": [
    "{'type': 'text', 'source': '在 :numref:`sec_linear_regression` 中我们介绍了线性回归。那么小批量特征为 $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ ，权重为 $\\mathbf{W} \\in \\mathbb{R}^{d \\times q}$。\\n'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-franklin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
