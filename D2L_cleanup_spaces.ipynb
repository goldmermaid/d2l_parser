{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flexible-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "from d2lbook import config, markdown, utils, common\n",
    "import logging\n",
    "import re\n",
    "import glob\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "clear-consensus",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipdb\n",
      "  Downloading ipdb-0.13.9.tar.gz (16 kB)\n",
      "Requirement already satisfied: setuptools in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from ipdb) (52.0.0.post20210125)\n",
      "Requirement already satisfied: ipython>=7.17.0 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from ipdb) (7.21.0)\n",
      "Collecting toml>=0.10.2\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: decorator in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from ipdb) (4.4.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb) (3.0.17)\n",
      "Requirement already satisfied: pickleshare in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb) (0.7.5)\n",
      "Requirement already satisfied: appnope in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb) (0.1.2)\n",
      "Requirement already satisfied: backcall in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb) (0.2.0)\n",
      "Requirement already satisfied: pygments in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb) (2.8.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb) (0.18.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from ipython>=7.17.0->ipdb) (5.0.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.17.0->ipdb) (0.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.17.0->ipdb) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0->ipdb) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /Users/rlhu/miniconda3/envs/d2l/lib/python3.8/site-packages (from traitlets>=4.2->ipython>=7.17.0->ipdb) (0.2.0)\n",
      "Building wheels for collected packages: ipdb\n",
      "  Building wheel for ipdb (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ipdb: filename=ipdb-0.13.9-py3-none-any.whl size=11619 sha256=ef617c6498ca95b508534e91e1f9f6faecc676c63c7d6b8c3e4cec164b4d896b\n",
      "  Stored in directory: /Users/rlhu/Library/Caches/pip/wheels/d8/51/8c/3dceedacfd0f743f3736b3840d08b6746b6259deea98207ba4\n",
      "Successfully built ipdb\n",
      "Installing collected packages: toml, ipdb\n",
      "Successfully installed ipdb-0.13.9 toml-0.10.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-process",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cheap-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MarkdownText(object):\n",
    "#     def __init__(self):\n",
    "#         self.mapping = []\n",
    "\n",
    "# #     def _encode_pattern(self, pattern, text):\n",
    "# #         matched = set(re.findall(pattern, text))\n",
    "# # #         ipdb.set_trace()\n",
    "# #         print(matched)\n",
    "# #         for m in matched:\n",
    "# #             # another solution is use some special tokens and put them in\n",
    "# #             # the terminology. unfortuanly it doesn't work for amazon transcribe.\n",
    "# #             # So use a number instead, hope it will not be translated.\n",
    "# #             token = str(732293614+len(self.mapping))\n",
    "# #             text = text.replace(m, token)\n",
    "# #             self.mapping.append((m, token))\n",
    "# #         return text\n",
    "\n",
    "#     def record_math(self, text:str) -> str:\n",
    "# #         patterns = [\n",
    "# #             rf'(:{markdown.token}:`{markdown.token}`)', # mark\n",
    "# #                     rf'(`{markdown.token}`)',  # code\n",
    "# #                     rf'(\\${markdown.token}\\$)', # inline match\n",
    "# #                     rf'(\\[{markdown.basic_token}\\]\\({markdown.basic_token}\\))', # link\n",
    "# #                     ]\n",
    "# #         for p in patterns:\n",
    "# #             text = self._encode_pattern(p, text)\n",
    "# #         return text\n",
    "    \n",
    "#         math_patterns = rf'\\$.*?\\$' # inline latex math match\n",
    "# #         rf'/(\\${1,2})((?:\\\\.|[\\s\\S])*)\\1/'\n",
    "#         matched = set(re.findall(math_patterns, text))\n",
    "#         for m in matched:\n",
    "#             m_no_space = m.replace(' ', '')\n",
    "#             self.mapping.append((m, m_no_space))\n",
    "# #         return matched\n",
    "\n",
    "#     def remove_space(self, text:str) -> str:\n",
    "#         self.record_math(text)\n",
    "#         text = text.replace(' ','')\n",
    "#         for key, value in self.mapping:\n",
    "#             text = text.replace(value, key)\n",
    "#         text = text.replace(\":numref:\", \" :numref:\")\n",
    "#         text = text.replace(\":cite:\", \" :cite:\")\n",
    "#         return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "guilty-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkdownCleaning(object):\n",
    "    def __init__(self):\n",
    "        self.math_mapping = []\n",
    "        self.english_no_ref_no_math = []\n",
    "        self.math_patterns = rf'\\$.*?\\$'\n",
    "        self.ref_pattern = r':[a-z]*:`[a-z_]*`'\n",
    "        self.html_pattern = r'http[\\S]*html'\n",
    "        self.html_wrong_pattern = r'（http[\\S]*html）'\n",
    "        \n",
    "        \n",
    "    def remove_space(self, text:str) -> str:\n",
    "        text = text.replace(' ', '')\n",
    "        text = text.replace(\"(\", '（') # 半角到全角 half-width to full-width\n",
    "        text = text.replace(\")\", '）') # 半角到全角 half-width to full-width\n",
    "        return text\n",
    " \n",
    "    def record_math(self, text:str) -> str:  \n",
    "        \"\"\"\n",
    "        Example:\n",
    "        input text = \"$(\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ \"\n",
    "        self.math_mapping = ((\"$(\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ \", \n",
    "                              \"$(\\mathbf{X}\\in\\mathbb{R}^{n\\timesd}$\")) \n",
    "        \"\"\"\n",
    "        # find inline latex math match, record their original \n",
    "        # and \"removed space\" format in the mapping\n",
    "         \n",
    "        matched = set(re.findall(self.math_patterns, text))\n",
    "        for m in matched:\n",
    "            m_no_space = self.remove_space(m)\n",
    "            self.math_mapping.append((m, m_no_space))    \n",
    "        return matched\n",
    "    \n",
    "        \n",
    "    def find_noref_nomath_english(self, text:str) -> str:\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        input text = \"在(mdad da) :numref:`sec_linear_regression` 中我们介绍了线性回归mds ds。 \n",
    "                        mds那么小批量特征为 $(\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ ，\n",
    "                        权重为 $\\(mathbf{W} \\in \\mathbb{R}^{d \\times q}$。 \\n \"\n",
    "        output = ['mdad da', 'mds ds', 'mds']\n",
    "        \"\"\"\n",
    "        # find and replace inline references like\n",
    "        # numref:`...`, :eqref:`...`, :cite:`...` etc\n",
    "        text_ex_ref = re.sub(self.ref_pattern, '', text)\n",
    "        \n",
    "        # find and replace all inline math and references\n",
    "        text_ex_ref_ex_math = re.sub(self.math_patterns, '', text_ex_ref)\n",
    "        \n",
    "        # find all english in text, exclude inline math and references\n",
    "        list_of_english_no_ref_no_math = re.findall(r'[a-zA-Z][a-z A-Z]+[a-zA-Z]', text_ex_ref_ex_math)\n",
    "        \n",
    "        # find all english phases with space, record them in a list mapping\n",
    "        if len(list_of_english_no_ref_no_math)>0:\n",
    "            for eng in list_of_english_no_ref_no_math:\n",
    "                if \" \" in eng:\n",
    "                    eng_no_space = eng.replace(' ', '')\n",
    "                    self.english_no_ref_no_math.append((eng, eng_no_space))\n",
    "        return list_of_english_no_ref_no_math\n",
    "        \n",
    "    def recover_html_parentheses(self, text:str) -> str:\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        input text: 参见[关于分布的在线附录]（https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html）\n",
    "        output text: 参见[关于分布的在线附录](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html)\n",
    "        \"\"\"\n",
    "        wrong_html_matched = set(re.findall(self.html_wrong_pattern, text))\n",
    "        for html in wrong_html_matched:\n",
    "            if html[0]==\"（\" and html[-1]==\"）\":\n",
    "                corrected_html = \"(\" + html[1:-1] + \")\"\n",
    "                text = re.sub(html, corrected_html, text)\n",
    "        return text\n",
    "                \n",
    "        \n",
    "    def clean_and_recover(self, text:str) -> str:\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        input text: \"在(mdad da) :numref:`sec_linear_regression` 中我们介绍了线性回归mds ds。\n",
    "                     mds那么小批量特征为 $(\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ ，\n",
    "                     分布（参见[关于分布的在线附录](https://d2l.ai/chapter_appendix-mathematics-\n",
    "                     for-deep-learning/distributions.html)）模型中。 \\n \"\n",
    "        \n",
    "        output text: \"在（mdad da） :numref:`sec_linear_regression`中我们介绍了线性回归mds ds。\n",
    "                      mds那么小批量特征为$(\\\\mathbf{X} \\\\in \\\\mathbb{R}^{n \\times d}$，\n",
    "                      分布（参见[关于分布的在线附录](https://d2l.ai/chapter_appendix-mathematics-\n",
    "                      for-deep-learning/distributions.html)）模型中。\\n'\n",
    "        \"\"\"\n",
    "        _ = self.record_math(text)\n",
    "        _ = self.find_noref_nomath_english(text)\n",
    "        text = self.remove_space(text)\n",
    "        # recover all the math with spaces\n",
    "        for key, value in self.math_mapping:\n",
    "            text = text.replace(value, key)\n",
    "            \n",
    "        # recover all the reference (like :numref:`...`) with spaces\n",
    "        for key, value in self.english_no_ref_no_math:\n",
    "#             # add a space in front of reference key (like \"numref\", \"eqref\", \"cite\"),\n",
    "#             # or the html won't compile\n",
    "#             new_key = \" \"+key\n",
    "#             text = text.replace(value, new_key)\n",
    "            text = text.replace(value, key) \n",
    "    \n",
    "        # recover htmls wrong parentheses to be [xxx](htmls:...)\n",
    "        text = self.recover_html_parentheses(text)\n",
    "            \n",
    "        # recover some ref (or the html won't compile)\n",
    "        text = text.replace(\":numref:\", \" :numref:\")\n",
    "        text = text.replace(\":eqref:\", \" :eqref:\")\n",
    "        text = text.replace(\":cite:\", \" :cite:\")\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "comfortable-perry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在（mdad da） :numref:`sec_linear_regression`中我们介绍了线性回归mds ds。mds那么小批量特征为$(\\\\mathbf{X} \\\\in \\\\mathbb{R}^{n \\times d}$，分布（参见[关于分布的在线附录](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html)）模型中。\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = MarkdownCleaning()\n",
    "ex_text = \"在(mdad da) :numref:`sec_linear_regression` 中我们介绍了线性回归mds ds。 mds 那么小批量特征为 $(\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ ，分布（参见[关于分布的在线附录](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html)）模型中。 \\n \"\n",
    "# ex_text_encode = mt.record_math(ex_text)\n",
    "ex_text_nex = mc.clean_and_recover(ex_text)\n",
    "ex_text_nex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bored-desperate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mdad da', 'mds ds', 'mds']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mc.find_noref_nomath_english(ex_text)\n",
    "# re.findall(r'[a-zA-Z][a-z A-Z]+', out)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "nominated-socket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mdad da', 'mdadda'),\n",
       " ('mds ds', 'mdsds'),\n",
       " ('mdad da', 'mdadda'),\n",
       " ('mds ds', 'mdsds')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.english_no_ref_no_math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "referenced-photograph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am from\n",
      "We should be friends\n",
      "softmax\n"
     ]
    }
   ],
   "source": [
    "sample = 'I am from 美国。We should be friends. 朋友softmax 。'\n",
    "for n in re.findall(r'[a-zA-Z][a-z A-Z]*[a-zA-Z]', sample):\n",
    "    print(n)\n",
    "\n",
    "# for n in re.findall(r'[\\u4e00-\\u9fff]+', sample):\n",
    "#     print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "valued-possible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":numref:`sec_linear_regression`\n"
     ]
    }
   ],
   "source": [
    "for n in re.findall(r':[a-z]*:`[a-z_]*`', ex_text):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "approximate-termination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "（https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html）\n"
     ]
    }
   ],
   "source": [
    "ex_html = \"分布（参见[关于分布的在线附录]（https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html））模型中\"\n",
    "for n in re.findall(r'（http[\\S]*html）', ex_html):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "continental-constitution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分布（参见[关于分布的在线附录](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html)）模型中'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_html = \"分布（参见[关于分布的在线附录]（https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/distributions.html））模型中\"\n",
    "mc = MarkdownCleaning()\n",
    "ex_html_nex = mc.clean_and_recover(ex_html)\n",
    "ex_html_nex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-ocean",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-convergence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-familiar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-deficit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-better",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-coordinator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-stake",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "trained-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator():\n",
    "    def _translate_markdown(self, text):\n",
    "            cells = markdown.split_markdown(text)\n",
    "            for cell in cells:\n",
    "                if cell['type'] == 'markdown':\n",
    "                    if 'class' in cell and cell['class']:\n",
    "                        # it may have nested code blocks\n",
    "                        cell['source'] = self._translate_markdown(cell['source'])\n",
    "                    else:\n",
    "                        text_cells = markdown.split_text(cell['source'])\n",
    "                        for t_cell in text_cells:\n",
    "#                             ipdb.set_trace()\n",
    "                            if t_cell['source'] and (\n",
    "                                t_cell['type'] in ['text', 'list']):\n",
    "                                text = t_cell['source']\n",
    "                                markdown_cleaning = MarkdownCleaning()\n",
    "                                t_cell['source'] = markdown_cleaning.clean_and_recover(text)\n",
    "#                                 if text.endswith('\\n'):\n",
    "#                                     t_cell['source'] += '\\n'\n",
    "                        cell['source'] = markdown.join_text(text_cells)\n",
    "            return markdown.join_markdown_cells(cells)\n",
    "\n",
    "    def translate_markdown(self, source_file: str, target_file: str):\n",
    "        with open(source_file, 'r') as r:\n",
    "            with open(target_file, 'w') as w:\n",
    "                w.write(self._translate_markdown(r.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "greenhouse-impossible",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Wrong title format:\n",
      "## 全连接层的参数开销\n",
      ":label:`subsec_parameterization-cost-fc-layers`\n",
      "正如我们将在后续章节中看到的，在深度学习中，全连接层无处不在。\n",
      "然而，顾名思义，全连接层是“完全”连接的，可能有很多可学习的参数。\n",
      "具体来说，对于任何具有$d$个输入和$q$个输出的全连接层，参数开销为$\\mathcal{O}(dq)$，在实践中可能高得令人望而却步。\n",
      "幸运的是，将$d$个输入转换为$q$个输出的成本可以减少到$\\mathcal{O}(\\frac{dq}{n})$，其中超参数$n$可以由我们灵活指定，以在实际应用中平衡参数节约和模型有效性 :cite:`Zhang.Tay.Zhang.ea.2021` 。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src = \"softmax-regression.md\"\n",
    "tgt = \"softmax-regression_new_new.md\"\n",
    "\n",
    "translator = Translator()\n",
    "translator.translate_markdown(src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-scott",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-marking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-survival",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-update",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-peace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fifty-modern",
   "metadata": {},
   "source": [
    "{'type': 'title', 'prefix': '# ', 'source': 'softmax回归', 'mark': ':label:`sec_softmax`\\n'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-settle",
   "metadata": {},
   "source": [
    "{'type': 'text', 'source': '在 :numref:`sec_linear_regression` 中我们介绍了线性回归。那么小批量特征为 $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ ，权重为 $\\mathbf{W} \\in \\mathbb{R}^{d \\times q}$。\\n'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-franklin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
